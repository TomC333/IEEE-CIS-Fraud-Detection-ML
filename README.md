# IEEE-CIS-Fraud-Detection-ML

## Kaggle-ის კონკურსის მიმოხილვა

ამ კონკურსის მიზანია, რომ აღმოვაჩნოთ ყალბი ტრანზაქციები.

## მიდგომა პრობლემის გადასაჭრელად

გადავწყვიტე ყველაფერი მონაცემთა ანალიზით დამეწყო, რათა გამომევლინა ის მახასიათებლები რომლებიც ყველაზე დიდი გავლენას ახდენს შედეგზე. ამ პროცესსში გამოვიყენე pandas, matplotlib ბიბლიოთეკები, ვიზუალიზაციისთვის. შემდეგ კი სხვადასხვა მოდელებისთვის გამოვიყენე მიდგომები - cleaning, feature engineering, feature selection.

## რეპოზიტორიის სტრუქტურა

- **model_experiment_{model}.ipynb** - მოდელების დამუშავების მთელი პროცესი: cleaning, feature engineering, feature selection, training.
- **model_inference.ipynb** - არჩეული მოდელის ტესტირება და პროგნოზების დალოგვა.
- **input/** - ფოლდერი სადაც ვინახავთ train და test csv ფაილებს.
- **models/** - ფოლდერი სადაც ვინახავთ დატრეინებულ მოდელებს

## Feature Engineering

### Cleaning & NaN Values 

მონაცემთა ანალიზის დროს, ძალიან ბევრ მახასიათებელს ჰქონდა NaN მნიშვნელობები ძალიან დიდი პროცენტულობით, ამ მნიშვნელობების დასამუშავებლად, ერთ მოდელში რიცხვითი მნიშვნელობები შევავსე mean-ით, მეორეში კი median-ით, კატეგორიული ცვლადების შემთხვევასი კი ერთგან ყველა ნან მნიშვნელობა ყველაზე ხშირად არსებულით, ერთგან კი Unknown მნიშვნელობებით, ხოლო XGBoost მოდელის შემთხვევაში ნან მნიშვნელობები საერთოდ არ გამითვალისწინებია ვინაიდან თავად მოდელის შიგნით არსებული ალგორითმი ჰენდლავს მსგავს მნიშვნელობებს (რამდედანც ვიცი....)

### Outliers

ანალიზის დროს ასეთი წერტილები სამწუახორდ ვერ ვიპოვე...


### კატეგორიული ცვლადების რიცხვითში გადაყვანა

სამივე მოდელის შემთხვევაში (თუ სწორად მახსოვს) გამოვიყენე label encoder რომლითაც თითოეული კატეგორიული ცვლადი გადავიყვანე რიცხვით ცვლადში.. თუმცა იყო ისეთი შემთხვევებიც როდესაც test სეტში არსებობდა მახასიათებლის კონკრეტული მნიშვნელობა რომელიც არ გვხვდებოდა train სეტში, prediction - ის დროს ერორების თავიდან ასაცილებლად უბრალოდ ყველა შესაძლო ვარიანტზე გამოვიყენე label enocder.

### ახალი მახასიათებლების შექმნა 

დატაფრეიმის მახასიათებლების გაანალიზებისას სამწუხაროდ არანაირი ახალი featur არ მომაფიქრდა, გარდა რამდენიმესა, როგორებიცაა Transaction_hour, Transaction_dayofweek, რატომღაც ჩავთვალე რომ ამას შეიძლება მნიშვნელობა ჰქონოდა ყალბი ტრანზაქციების შემთხვევაში, ვფიქრობდი რომ შესაზლოა ყალბი ტრანზაქციების უმეტესობა დღის რომელიღაც კონკრეტულ მონაკვეთში ხდებოდა... სხვადასხვა მოდელებში სხვა რამდენიმე ახალი მახასიათებელიც შევქმენი.

## Feature Selection

ამ შემთხვევაში, დატაფრეიმის ანალიზი დიდად არ გამომადგა, ყველა მახასიათებელი საკმაოდ დაბალ კორელაციაში იყო isFraud feature-თან, ამიტომ ბევრი არ მიფიქრია და ერთ შემთხვევაში ავირჩიე უბრალოდ ყველა მახასიათებელი, რომელთა კორელაცია 0.1 ზე მეტი იყო, რენდომ ფორესტის შემთხვევაში მახასიათებლების ტოპ 70% ავირჩიე, ხოლო XGBoost ის შემთხვევაში XBGClassifier გამოვიყენე...ს


## Training

ყველა შემთხვევაში ტრეინ დატასეტი ორ ნაწილად გავყავი, ტრეინინგისთვის და ვალიდაციისთვის, LogisticRegression-ის შემთხვევაში უბრალოდ დავატრეინე მოდელი ტრეინ სეტზე, ხოლო RandomForest-ისა და XGBoost-ის შემთხვევაში ჰიპერპარამეტრების ოპტიმიზაცია გამოვიყენე რათა მეპოვა "საუკეთესო" ვარიანტი.


## საბოლოო მოდელის შერჩევa 

საბოლოო მოდელად ავარჩიე **XGBoost**. რადგან უბრალოდ ყველაზე კარგი შედეგები აჩვენა... საბმიშენზეც ყველაზე მაღალი ქულა ამ მოდელს ქონდა.

